{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aad851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import traceback\n",
    "import json\n",
    "import tqdm\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652ed50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"./data/data.parquet\")\n",
    "data = data.with_columns(\n",
    "    pl.arange(1, data.height + 1).alias(\"item_id\")\n",
    ")\n",
    "category_description = data[[\"item_id\",\"description\"]].to_dict(as_series=False)\n",
    "items = [dict(zip(category_description.keys(), values)) for values in zip(*category_description.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24831404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BATCH_SIZE = 5\n",
    "# Update this to your llama.cpp server endpoint\n",
    "LLAMA_CPP_BASE_URL = \"http://localhost:8080/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c13082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemReview(BaseModel):\n",
    "    item_id: int = Field(description=\"unique identifier that is provided in the input.\", title=\"item_id\")\n",
    "    classification: str = Field(description=\"The classification of the item (e.g.,Food,cloths).\")\n",
    "    review: str = Field(description=\"A brief review of the item.\")\n",
    "\n",
    "class Response(BaseModel):\n",
    "    reviews: List[ItemReview] = Field(min_length=BATCH_SIZE, description=\"A list of classifications and reviews for the provided items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb643e58",
   "metadata": {},
   "source": [
    "## Using AsyncIO with llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed6f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the async OpenAI client for llama.cpp\n",
    "client = AsyncOpenAI(\n",
    "    api_key=\"sk-no-key-required\",  # llama.cpp doesn't require a real API key\n",
    "    base_url=LLAMA_CPP_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0baf1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Chat(client, context):\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=context,\n",
    "        model=\"gpt-3.5-turbo\",  # This is ignored by llama.cpp, it uses whatever model is loaded\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=1,\n",
    "        max_tokens=4000,\n",
    "        timeout=60\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7616c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_text(items: list[dict]) -> str:\n",
    "    lines = []\n",
    "    for item in items:\n",
    "        line = \"\\n\".join([f\"{key} : {value}\" for key, value in item.items()])\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4dca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrompt(batch_items):\n",
    "    prompt_instruction = \"\"\"\n",
    "                You are a helpful assistant that classifies and reviews items.\n",
    "                \n",
    "                Each item has:\n",
    "                - \"item_id\": unique id for each item\n",
    "                - \"description\": the item's description\n",
    "                \n",
    "                Return a JSON object with a \"reviews\" array containing objects with the following keys:\n",
    "                - \"item_id\" : same as item_id from input\n",
    "                - \"classification\" : classification of item category  \n",
    "                - \"review\" : small review 1-2 phrases max\n",
    "                \n",
    "                Example format:\n",
    "                {\n",
    "                  \"reviews\": [\n",
    "                    {\n",
    "                      \"item_id\": 1,\n",
    "                      \"classification\": \"Electronics\",\n",
    "                      \"review\": \"Great product with excellent features.\"\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "                \"\"\"\n",
    "    \n",
    "    # Build prompt\n",
    "    number_of_items = len(batch_items)\n",
    "    batch_items_text = dict_to_text(batch_items)\n",
    "    context = [\n",
    "                {'role': 'system',\n",
    "                 'content': f\"{prompt_instruction}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"The following {number_of_items} items need to be classified and reviewed. Please return exactly {number_of_items} reviews in JSON format:\\n\\n{batch_items_text}\"},\n",
    "            ]\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2692d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(result, BATCH_SIZE, batch_items):\n",
    "    if len(result[\"reviews\"]) != BATCH_SIZE:\n",
    "        print(f\"Expected {len(batch_items)} reviews, but got {len(result['reviews'])} \\nwhat i got : {result} , handling error\")\n",
    "        \n",
    "        items_ids = [r[\"item_id\"] for r in result[\"reviews\"]] \n",
    "        rest = [item for item in batch_items if item[\"item_id\"] not in items_ids]\n",
    "    else:\n",
    "        rest = None\n",
    "    return rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe70d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def batch_iter(iterable, BATCH_SIZE):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        batch = list(islice(it, BATCH_SIZE))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e03b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use async io to send multiple batches at the same time \n",
    "# using llama.cpp with OpenAI client\n",
    "async def main():\n",
    "    \n",
    "    all_reviews = []\n",
    "    rest = None\n",
    "    items_iter = batch_iter(items, BATCH_SIZE)\n",
    "    \n",
    "    # Initialize progress bar\n",
    "    total_items = len(items)\n",
    "    pbar = tqdm.tqdm(total=total_items, desc=\"Processing items\", unit=\"items\")\n",
    "    processed_count = 0\n",
    "    end = False\n",
    "    while end is False:\n",
    "        if rest:\n",
    "            batches = [rest]\n",
    "            rest = None\n",
    "        else:\n",
    "            # Process fewer concurrent batches for llama.cpp to avoid overwhelming the server\n",
    "            batches = [list(next(items_iter, [])) for _ in range(5)]  # Reduced from 20 to 5\n",
    "            batches = [b for b in batches if b]  # remove empty\n",
    "\n",
    "        if not batches:\n",
    "            break\n",
    "\n",
    "        contexts = [createPrompt(b) for b in batches]\n",
    "        responses = await asyncio.gather(*(Chat(client, ctx) for ctx in contexts), return_exceptions=True)\n",
    "\n",
    "        for batch_items, response in zip(batches, responses):\n",
    "            try:\n",
    "                    \n",
    "                # Parse the response content\n",
    "                content = response.choices[0].message.content\n",
    "                result = json.loads(content)\n",
    "                \n",
    "                # Validate with pydantic\n",
    "                validated_response = Response.model_validate(result)\n",
    "                result = json.loads(validated_response.model_dump_json())\n",
    "                \n",
    "                rest = retry(result, BATCH_SIZE, batch_items)\n",
    "                \n",
    "                # Only count as processed if no retry is needed\n",
    "                if rest is None:\n",
    "                    items_processed = len(batch_items)\n",
    "                    processed_count += items_processed\n",
    "                    pbar.update(items_processed)\n",
    "                    pbar.set_postfix({\"Processed\": processed_count, \"Reviews\": len(all_reviews)})\n",
    "                \n",
    "                all_reviews.extend(result[\"reviews\"])\n",
    "                end = True\n",
    "                break\n",
    "                \n",
    "            except json.JSONDecodeError as jd:\n",
    "                # print(f\"JSONDecodeError: {jd}\")\n",
    "                # print(f\"Response content: {response.choices[0].message.content if hasattr(response, 'choices') else 'No content'}\")\n",
    "                rest = batch_items  # Retry this batch\n",
    "            except ValueError as ve:\n",
    "                #print(f\"ValueError: {ve}\")\n",
    "                rest = batch_items  # Retry this batch\n",
    "            except Exception as e:\n",
    "                #print(f\"Unexpected error: {e}\")\n",
    "                #print(f\"Response: {response}\")\n",
    "                rest = batch_items  # Retry this batch\n",
    "\n",
    "    pbar.close()\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf5e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|          | 5/1000000 [00:16<940:18:23,  3.39s/items, Processed=5, Reviews=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews collected: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "reviews = await main()\n",
    "print(f\"Total reviews collected: {len(reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac54974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send one request\n",
    "\n",
    "async def send_request(client, item):\n",
    "    prompt = createPrompt(item)\n",
    "    response = await Chat(client, prompt)\n",
    "    content = response.choices[0].message.content\n",
    "    result = json.loads(content)\n",
    "    \n",
    "    # Validate with pydantic\n",
    "    # validated_response = Response.model_validate(result)\n",
    "    # result = json.loads(validated_response.model_dump_json())\n",
    "    return result\n",
    "\n",
    "# run \n",
    "# res = await send_request(client, [item])\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49f65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c52bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a282da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b517e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
